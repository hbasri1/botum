#!/usr/bin/env python3
"""
Mevcut √úr√ºn Arama Sistemi Analizi
"""

import json
from rapidfuzz import fuzz

def analyze_current_search():
    """Mevcut arama sistemini analiz et"""
    
    print("üîç Mevcut √úr√ºn Arama Sistemi Analizi")
    print("=" * 50)
    
    # √úr√ºnleri y√ºkle
    with open("data/products.json", "r", encoding="utf-8") as f:
        products = json.load(f)
    
    print(f"üì¶ Toplam √úr√ºn Sayƒ±sƒ±: {len(products)}")
    
    # ƒ∞lk 5 √ºr√ºn√º g√∂ster
    print("\nüìã √ñrnek √úr√ºnler:")
    for i, product in enumerate(products[:5]):
        print(f"   {i+1}. {product['name']}")
        print(f"      Fiyat: {product.get('final_price', 'N/A')} TL")
        print(f"      Kategori: {product.get('category', 'N/A')}")
        print(f"      Renk: {product.get('color', 'N/A')}")
        print()
    
    # Arama algoritmasƒ± testi
    print("üß™ Arama Algoritmasƒ± Testi:")
    test_queries = [
        "afrika gecelik",
        "afrika geceliƒüi", 
        "hamile pijama",
        "siyah gecelik",
        "dantelli gecelik"
    ]
    
    for query in test_queries:
        print(f"\nüîç Sorgu: '{query}'")
        
        # Normalize et
        normalized_query = normalize_turkish_text(query)
        print(f"   Normalize: '{normalized_query}'")
        
        # En iyi e≈üle≈ümeleri bul
        matches = []
        for product in products:
            product_name_normalized = normalize_turkish_text(product["name"])
            score = fuzz.token_set_ratio(normalized_query, product_name_normalized)
            
            if score > 75:
                matches.append((product, score))
        
        # Sƒ±rala
        matches.sort(key=lambda x: x[1], reverse=True)
        
        print(f"   Sonu√ß: {len(matches)} e≈üle≈üme")
        for i, (product, score) in enumerate(matches[:3]):
            print(f"      {i+1}. {product['name']} (Skor: {score})")

def normalize_turkish_text(text):
    """Basit T√ºrk√ße normalizasyon"""
    if not text:
        return ""
    
    text = text.lower().strip()
    
    # T√ºrk√ße ekleri temizle
    replacements = {
        'geceliƒüi': 'gecelik', 'geceliƒüin': 'gecelik',
        'pijamayƒ±': 'pijama', 'pijamanƒ±n': 'pijama',
        'elbiseyi': 'elbise', 'elbisenin': 'elbise',
        'sabahlƒ±ƒüƒ±': 'sabahlƒ±k', 'sabahlƒ±ƒüƒ±n': 'sabahlƒ±k'
    }
    
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    return text

def show_search_flow():
    """Arama akƒ±≈üƒ±nƒ± g√∂ster"""
    print("\nüîÑ Mevcut Arama Akƒ±≈üƒ±:")
    print("1. Kullanƒ±cƒ± sorgusu: 'afrika geceliƒüi'")
    print("2. LLM Service: _extract_product_name() ‚Üí 'afrika gecelik'")
    print("3. Database Service: get_product_info() √ßaƒürƒ±lƒ±r")
    print("4. Normalizasyon: 'afrika geceliƒüi' ‚Üí 'afrika gecelik'")
    print("5. Fuzzy Matching: T√ºm √ºr√ºnlerle kar≈üƒ±la≈ütƒ±r")
    print("6. En y√ºksek skor (>75): √úr√ºn√º d√∂nd√ºr")
    print("7. Product Handler: Response formatla")
    print("8. Kullanƒ±cƒ±ya cevap")
    
    print("\n‚ö†Ô∏è Mevcut Sorunlar:")
    print("‚Ä¢ Sadece fuzzy matching (semantic yok)")
    print("‚Ä¢ T√ºrk√ße normalizasyon eksik")
    print("‚Ä¢ Context awareness yok")
    print("‚Ä¢ Personalization yok")
    print("‚Ä¢ Synonym handling yok")

if __name__ == "__main__":
    analyze_current_search()
    show_search_flow()