#!/usr/bin/env python3
"""
Enhanced Query Processor - Sistemik query iÅŸleme sistemi
"""

import re
import logging
from typing import Dict, List, Optional, Set
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ProductFeature:
    """ÃœrÃ¼n Ã¶zelliÄŸi modeli"""
    name: str
    category: str
    weight: float
    synonyms: List[str]

@dataclass
class ProcessedQuery:
    """Ä°ÅŸlenmiÅŸ query modeli"""
    original: str
    normalized: str
    features: List[ProductFeature]
    expanded_terms: List[str]
    query_type: str

class QueryProcessor:
    """Sistemik query iÅŸleme sistemi"""
    
    def __init__(self):
        self.feature_patterns = self._load_feature_patterns()
        self.turkish_normalizations = self._load_turkish_normalizations()
        self.synonym_mappings = self._load_synonym_mappings()
        self.query_type_patterns = self._load_query_type_patterns()
    
    def _load_feature_patterns(self) -> Dict[str, List[str]]:
        """ÃœrÃ¼n Ã¶zellik pattern'lerini yÃ¼kle"""
        return {
            'dekolte_types': [
                'gÃ¶ÄŸÃ¼s dekolteli', 'sÄ±rt dekolteli', 'gÃ¶ÄŸÃ¼s ve sÄ±rt dekolteli',
                'v yaka', 'aÃ§Ä±k yaka', 'derin yaka', 'dekolteli', 'dekolte'
            ],
            'product_types': [
                'takÄ±m', 'set', 'pijama', 'gecelik', 'sabahlÄ±k', 'ÅŸort',
                'elbise', 'bluz', 'pantolon', 'tiÅŸÃ¶rt', 'kazak'
            ],
            'materials': [
                'dantelli', 'dantel', 'brode', 'brodeli', 'saten', 'pamuk',
                'viskon', 'modal', 'polyester', 'elastan', 'ipek'
            ],
            'styles': [
                'etnik', 'afrika', 'desenli', 'dÃ¼z', 'Ã§izgili', 'puantiyeli',
                'Ã§iÃ§ekli', 'geometrik', 'vintage', 'modern', 'klasik'
            ],
            'colors': [
                'siyah', 'beyaz', 'kÄ±rmÄ±zÄ±', 'mavi', 'yeÅŸil', 'sarÄ±', 'pembe',
                'mor', 'lacivert', 'bordo', 'bej', 'ekru', 'gri', 'krem'
            ],
            'sizes': [
                'xs', 's', 'm', 'l', 'xl', 'xxl', 'kÃ¼Ã§Ã¼k', 'orta', 'bÃ¼yÃ¼k'
            ],
            'occasions': [
                'hamile', 'lohusa', 'anne', 'gebelik', 'emzirme', 'doÄŸum',
                'gÃ¼nlÃ¼k', 'Ã¶zel', 'gece', 'gÃ¼ndÃ¼z', 'spor', 'rahat'
            ]
        }
    
    def _load_turkish_normalizations(self) -> Dict[str, str]:
        """TÃ¼rkÃ§e normalizasyon kurallarÄ±"""
        return {
            # Hal ekleri
            'geceliÄŸi': 'gecelik', 'geceliÄŸin': 'gecelik', 'geceliÄŸe': 'gecelik',
            'pijamayÄ±': 'pijama', 'pijamanÄ±n': 'pijama', 'pijamaya': 'pijama',
            'elbiseyi': 'elbise', 'elbisenin': 'elbise', 'elbiseye': 'elbise',
            'sabahlÄ±ÄŸÄ±': 'sabahlÄ±k', 'sabahlÄ±ÄŸÄ±n': 'sabahlÄ±k', 'sabahlÄ±ÄŸa': 'sabahlÄ±k',
            'takÄ±mÄ±': 'takÄ±m', 'takÄ±mÄ±n': 'takÄ±m', 'takÄ±ma': 'takÄ±m', 'takimi': 'takÄ±m',
            'ÅŸortu': 'ÅŸort', 'ÅŸortun': 'ÅŸort', 'ÅŸorta': 'ÅŸort',
            
            # Ã‡oÄŸul ekleri
            'gecelikler': 'gecelik', 'pijamalar': 'pijama', 'elbiseler': 'elbise',
            'takÄ±mlar': 'takÄ±m', 'ÅŸortlar': 'ÅŸort',
            
            # YaygÄ±n yazÄ±m hatalarÄ±
            'afirka': 'afrika', 'afrik': 'afrika', 'africa': 'afrika',
            'danteli': 'dantelli', 'dantel': 'dantelli',
            'hamil': 'hamile', 'lohsa': 'lohusa',
            'dekolte': 'dekolteli', 'dekolte': 'dekolteli',
            'pijma': 'pijama', 'geclik': 'gecelik'
        }
    
    def _load_synonym_mappings(self) -> Dict[str, List[str]]:
        """Synonym mapping'leri yÃ¼kle"""
        return {
            'takÄ±m': ['set', 'komple', 'alt Ã¼st', 'eÅŸofman'],
            'gecelik': ['nightgown', 'gece elbisesi', 'uyku elbisesi'],
            'pijama': ['pajama', 'uyku kÄ±yafeti', 'ev kÄ±yafeti'],
            'sabahlÄ±k': ['robe', 'bornoz', 'ev mantolu'],
            'dekolteli': ['aÃ§Ä±k', 'derin yaka', 'v yaka'],
            'dantelli': ['gÃ¼pÃ¼rlÃ¼', 'iÅŸlemeli', 'sÃ¼slÃ¼'],
            'afrika': ['etnik', 'tribal', 'desenli'],
            'hamile': ['gebelik', 'anne adayÄ±', 'pregnant'],
            'lohusa': ['emziren', 'yeni anne', 'doÄŸum sonrasÄ±']
        }
    
    def _load_query_type_patterns(self) -> Dict[str, List[str]]:
        """Query type pattern'lerini yÃ¼kle"""
        return {
            'price': ['fiyat', 'kaÃ§ para', 'ne kadar', 'price', 'Ã¼cret', 'tutar'],
            'stock': ['stok', 'var mÄ±', 'mevcut', 'stock', 'kaldÄ±', 'bulunur'],
            'detail': ['detay', 'bilgi', 'Ã¶zellik', 'nasÄ±l', 'info', 'hakkÄ±nda'],
            'color': ['renk', 'color', 'renkler', 'hangi renk', 'ne renk'],
            'size': ['beden', 'size', 'bedenleri', 'hangi beden', 'boyut'],
            'search': ['ara', 'bul', 'gÃ¶ster', 'search', 'find', 'show']
        }
    
    def normalize_turkish(self, text: str) -> str:
        """TÃ¼rkÃ§e metni normalize et"""
        if not text:
            return ""
        
        text = text.lower().strip()
        
        # TÃ¼rkÃ§e normalizasyonlarÄ± uygula
        for old, new in self.turkish_normalizations.items():
            text = text.replace(old, new)
        
        # Fazla boÅŸluklarÄ± temizle
        text = re.sub(r'\s+', ' ', text)
        
        return text
    
    def extract_features(self, query: str) -> List[ProductFeature]:
        """Query'den Ã¼rÃ¼n Ã¶zelliklerini Ã§Ä±kar"""
        features = []
        normalized_query = self.normalize_turkish(query)
        
        for category, patterns in self.feature_patterns.items():
            for pattern in patterns:
                if pattern in normalized_query:
                    # Ã–zellik aÄŸÄ±rlÄ±ÄŸÄ±nÄ± hesapla
                    weight = self._calculate_feature_weight(pattern, category, normalized_query)
                    
                    # Synonym'leri al
                    synonyms = self.synonym_mappings.get(pattern, [])
                    
                    feature = ProductFeature(
                        name=pattern,
                        category=category,
                        weight=weight,
                        synonyms=synonyms
                    )
                    features.append(feature)
        
        return features
    
    def _calculate_feature_weight(self, pattern: str, category: str, query: str) -> float:
        """Ã–zellik aÄŸÄ±rlÄ±ÄŸÄ±nÄ± hesapla"""
        base_weight = 1.0
        
        # Kategori bazlÄ± aÄŸÄ±rlÄ±k
        category_weights = {
            'dekolte_types': 1.5,  # Ã‡ok spesifik Ã¶zellik
            'product_types': 1.3,  # Ã–nemli kategori
            'materials': 1.2,      # Orta Ã¶nemli
            'styles': 1.1,         # Az Ã¶nemli
            'colors': 1.0,         # Temel Ã¶zellik
            'sizes': 0.9,          # Daha az Ã¶nemli
            'occasions': 1.4       # Ã–zel durumlar (hamile vs.)
        }
        
        weight = base_weight * category_weights.get(category, 1.0)
        
        # Query'deki pozisyona gÃ¶re aÄŸÄ±rlÄ±k
        words = query.split()
        if pattern in words[:3]:  # Ä°lk 3 kelimede
            weight *= 1.2
        
        # Tam kelime eÅŸleÅŸmesi bonusu
        if f" {pattern} " in f" {query} ":
            weight *= 1.1
        
        return weight
    
    def expand_query(self, query: str) -> str:
        """Query'yi synonym'lerle geniÅŸlet"""
        expanded_terms = []
        normalized_query = self.normalize_turkish(query)
        words = normalized_query.split()
        
        for word in words:
            expanded_terms.append(word)
            
            # Synonym'leri ekle
            if word in self.synonym_mappings:
                expanded_terms.extend(self.synonym_mappings[word])
        
        return " ".join(expanded_terms)
    
    def detect_query_type(self, query: str) -> str:
        """Query tipini tespit et"""
        normalized_query = self.normalize_turkish(query)
        
        for query_type, patterns in self.query_type_patterns.items():
            if any(pattern in normalized_query for pattern in patterns):
                return query_type
        
        # Default olarak search
        return 'search'
    
    def process_query(self, query: str, context: Optional[Dict] = None) -> ProcessedQuery:
        """Query'yi tam olarak iÅŸle"""
        try:
            # Normalize et
            normalized = self.normalize_turkish(query)
            
            # Context ile entegre et
            if context and context.get('last_product'):
                # Context varsa ve query belirsizse, context'i ekle
                if len(normalized.split()) <= 2:  # KÄ±sa query
                    normalized = f"{context['last_product']} {normalized}"
            
            # Ã–zellikleri Ã§Ä±kar
            features = self.extract_features(normalized)
            
            # Query'yi geniÅŸlet
            expanded = self.expand_query(normalized)
            
            # Query tipini tespit et
            query_type = self.detect_query_type(normalized)
            
            return ProcessedQuery(
                original=query,
                normalized=normalized,
                features=features,
                expanded_terms=expanded.split(),
                query_type=query_type
            )
            
        except Exception as e:
            logger.error(f"Query processing error: {str(e)}")
            # Fallback
            return ProcessedQuery(
                original=query,
                normalized=self.normalize_turkish(query),
                features=[],
                expanded_terms=query.split(),
                query_type='search'
            )
    
    def get_feature_summary(self, features: List[ProductFeature]) -> Dict[str, List[str]]:
        """Ã–zelliklerin Ã¶zetini al"""
        summary = {}
        for feature in features:
            if feature.category not in summary:
                summary[feature.category] = []
            summary[feature.category].append(feature.name)
        return summary

# Test fonksiyonu
def test_query_processor():
    """Query processor'Ä± test et"""
    
    print("ğŸ”§ Query Processor Test")
    print("=" * 40)
    
    processor = QueryProcessor()
    
    test_queries = [
        "gÃ¶ÄŸÃ¼s ve sÄ±rt dekolteli takÄ±m",
        "hamile lohusa pijamayÄ±",
        "afrika geceliÄŸi fiyatÄ±",
        "dantelli ÅŸort takimi var mÄ±",
        "brode sabahlÄ±ÄŸÄ±n stok durumu"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” Query: '{query}'")
        
        processed = processor.process_query(query)
        
        print(f"   Normalized: {processed.normalized}")
        print(f"   Type: {processed.query_type}")
        print(f"   Features: {len(processed.features)}")
        
        feature_summary = processor.get_feature_summary(processed.features)
        for category, features in feature_summary.items():
            print(f"     {category}: {', '.join(features)}")

if __name__ == "__main__":
    test_query_processor()