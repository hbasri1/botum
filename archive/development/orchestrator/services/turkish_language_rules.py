#!/usr/bin/env python3
"""
Turkish Language Rules - TÃ¼rkÃ§e dil kurallarÄ± ve normalizasyon
"""

import re
from typing import Dict, List, Set

class TurkishLanguageRules:
    """TÃ¼rkÃ§e dil kurallarÄ± ve normalizasyon sistemi"""
    
    def __init__(self):
        self._initialize_turkish_rules()
    
    def _initialize_turkish_rules(self):
        """TÃ¼rkÃ§e dil kurallarÄ±nÄ± initialize et"""
        
        # TÃ¼rkÃ§e ek normalizasyonu
        self.suffix_normalizations = {
            # Genitif ekleri
            r'\b(\w+)(nin|nÄ±n|nun|nÃ¼n)\b': r'\1',
            r'\b(\w+)(in|Ä±n|un|Ã¼n)\b': r'\1',
            
            # Accusative ekleri
            r'\b(\w+)(yi|yÄ±|yu|yÃ¼)\b': r'\1',
            r'\b(\w+)(i|Ä±|u|Ã¼)\b': r'\1',
            
            # Dative ekleri
            r'\b(\w+)(ye|ya)\b': r'\1',
            r'\b(\w+)(e|a)\b': r'\1',
            
            # Locative ekleri
            r'\b(\w+)(de|da)\b': r'\1',
            r'\b(\w+)(te|ta)\b': r'\1',
            
            # Ablative ekleri
            r'\b(\w+)(den|dan)\b': r'\1',
            r'\b(\w+)(ten|tan)\b': r'\1',
            
            # Plural ekleri
            r'\b(\w+)(ler|lar)\b': r'\1',
            
            # Possessive ekleri
            r'\b(\w+)(si|sÄ±|su|sÃ¼)\b': r'\1',
            r'\b(\w+)(i|Ä±|u|Ã¼)\b': r'\1'
        }
        
        # Ã–zel kelime normalizasyonlarÄ±
        self.word_normalizations = {
            'geceliÄŸi': 'gecelik',
            'geceliÄŸin': 'gecelik',
            'geceliÄŸe': 'gecelik',
            'gecelikler': 'gecelik',
            'gecelikleri': 'gecelik',
            
            'pijamayÄ±': 'pijama',
            'pijamanÄ±n': 'pijama',
            'pijamaya': 'pijama',
            'pijamalar': 'pijama',
            'pijamalarÄ±': 'pijama',
            
            'sabahlÄ±ÄŸÄ±': 'sabahlÄ±k',
            'sabahlÄ±ÄŸÄ±n': 'sabahlÄ±k',
            'sabahlÄ±ÄŸa': 'sabahlÄ±k',
            'sabahlÄ±klar': 'sabahlÄ±k',
            'sabahlÄ±klarÄ±': 'sabahlÄ±k',
            
            'takÄ±mÄ±': 'takÄ±m',
            'takÄ±mÄ±n': 'takÄ±m',
            'takÄ±ma': 'takÄ±m',
            'takÄ±mlar': 'takÄ±m',
            'takÄ±mlarÄ±': 'takÄ±m',
            
            'elbiseyi': 'elbise',
            'elbisenin': 'elbise',
            'elbiseye': 'elbise',
            'elbiseler': 'elbise',
            'elbiseleri': 'elbise',
            
            'dantelli': 'dantel',
            'dantelleri': 'dantel',
            'dantellerin': 'dantel',
            
            'tÃ¼llÃ¼': 'tÃ¼l',
            'tÃ¼lleri': 'tÃ¼l',
            'tÃ¼llerin': 'tÃ¼l',
            
            'pamuklu': 'pamuk',
            'pamuklarÄ±': 'pamuk',
            'pamuklarin': 'pamuk',
            
            'askÄ±lÄ±': 'askÄ±',
            'askÄ±larÄ±': 'askÄ±',
            'askÄ±larÄ±n': 'askÄ±',
            
            'dÃ¼ÄŸmeli': 'dÃ¼ÄŸme',
            'dÃ¼ÄŸmeleri': 'dÃ¼ÄŸme',
            'dÃ¼ÄŸmelerin': 'dÃ¼ÄŸme',
            
            'dekolteli': 'dekolte',
            'dekolteleri': 'dekolte',
            'dekoltelerin': 'dekolte'
        }
        
        # TÃ¼rkÃ§e karakter normalizasyonu
        self.character_normalizations = {
            'Ã§': 'c', 'Ã‡': 'C',
            'ÄŸ': 'g', 'Äž': 'G',
            'Ä±': 'i', 'I': 'I',
            'Ä°': 'I', 'i': 'i',
            'Ã¶': 'o', 'Ã–': 'O',
            'ÅŸ': 's', 'Åž': 'S',
            'Ã¼': 'u', 'Ãœ': 'U'
        }
        
        # TÃ¼rkÃ§e sinonimler
        self.turkish_synonyms = {
            'gecelik': ['nightgown', 'nightdress', 'gece elbisesi', 'uyku elbisesi'],
            'pijama': ['pajama', 'pyjama', 'ev kÄ±yafeti', 'uyku kÄ±yafeti'],
            'sabahlÄ±k': ['robe', 'bathrobe', 'morning gown', 'bornoz'],
            'takÄ±m': ['set', 'suit', 'kombin', 'eÅŸofman'],
            'elbise': ['dress', 'frock', 'gown'],
            'bluz': ['blouse', 'top', 'shirt'],
            'ÅŸort': ['shorts', 'short', 'kÄ±sa pantolon'],
            'pantolon': ['pants', 'trousers', 'jean'],
            
            'dantel': ['lace', 'gÃ¼pÃ¼r', 'dantela'],
            'tÃ¼l': ['tulle', 'mesh', 'file'],
            'pamuk': ['cotton', '100% pamuk', 'cotton blend'],
            'ipek': ['silk', 'satin', 'ipeksi'],
            'saten': ['satin', 'silk', 'parlak'],
            
            'siyah': ['black', 'kara', 'koyu'],
            'beyaz': ['white', 'ak', 'ekru', 'krem', 'bej'],
            'kÄ±rmÄ±zÄ±': ['red', 'al', 'bordo', 'crimson'],
            'mavi': ['blue', 'lacivert', 'navy', 'gÃ¶k'],
            'yeÅŸil': ['green', 'yemyeÅŸil', 'Ã§imen'],
            'sarÄ±': ['yellow', 'altÄ±n', 'gold', 'golden'],
            'pembe': ['pink', 'fuÅŸya', 'rose', 'gÃ¼l'],
            'mor': ['purple', 'lila', 'violet', 'menekÅŸe'],
            
            'hamile': ['pregnant', 'maternity', 'anne adayÄ±', 'gebe'],
            'lohusa': ['nursing', 'emziren', 'anne', 'postpartum'],
            
            'dekolteli': ['decollete', 'aÃ§Ä±k yakalÄ±', 'gÃ¶ÄŸÃ¼s aÃ§Ä±k'],
            'askÄ±lÄ±': ['strappy', 'strap', 'ip askÄ±lÄ±'],
            'dÃ¼ÄŸmeli': ['buttoned', 'button', 'dÃ¼ÄŸme'],
            'fermuarlÄ±': ['zipped', 'zipper', 'fermuar']
        }
        
        # TÃ¼rkÃ§e stopwords (arama iÃ§in Ã¶nemsiz kelimeler)
        self.stopwords = {
            've', 'ile', 'iÃ§in', 'olan', 'olarak', 'bu', 'ÅŸu', 'o',
            'bir', 'iki', 'Ã¼Ã§', 'dÃ¶rt', 'beÅŸ', 'altÄ±', 'yedi', 'sekiz', 'dokuz', 'on',
            'Ã§ok', 'az', 'biraz', 'oldukÃ§a', 'son', 'yeni', 'eski',
            'bÃ¼yÃ¼k', 'kÃ¼Ã§Ã¼k', 'orta', 'normal', 'standart',
            'model', 'tip', 'tÃ¼r', 'Ã§eÅŸit', 'stil', 'style'
        }
    
    def normalize_text(self, text: str) -> str:
        """
        TÃ¼rkÃ§e metni normalize et
        
        Args:
            text: Normalize edilecek metin
            
        Returns:
            str: Normalize edilmiÅŸ metin
        """
        if not text:
            return ""
        
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        normalized = text.lower().strip()
        
        # Ã–zel kelime normalizasyonlarÄ±
        words = normalized.split()
        normalized_words = []
        
        for word in words:
            # Stopwords'leri atla
            if word in self.stopwords:
                continue
            
            # Ã–zel kelime normalizasyonu
            if word in self.word_normalizations:
                normalized_words.append(self.word_normalizations[word])
            else:
                # Ek normalizasyonu
                normalized_word = self._normalize_suffixes(word)
                normalized_words.append(normalized_word)
        
        return ' '.join(normalized_words)
    
    def _normalize_suffixes(self, word: str) -> str:
        """TÃ¼rkÃ§e ekleri normalize et"""
        for pattern, replacement in self.suffix_normalizations.items():
            word = re.sub(pattern, replacement, word)
        return word
    
    def normalize_for_search(self, text: str) -> str:
        """Arama iÃ§in Ã¶zel normalizasyon"""
        normalized = self.normalize_text(text)
        
        # TÃ¼rkÃ§e karakterleri ASCII'ye Ã§evir (opsiyonel)
        # for turkish_char, ascii_char in self.character_normalizations.items():
        #     normalized = normalized.replace(turkish_char, ascii_char)
        
        return normalized
    
    def get_synonyms(self, word: str) -> List[str]:
        """Kelime iÃ§in sinonimlarÄ± getir"""
        normalized_word = self.normalize_text(word).strip()
        return self.turkish_synonyms.get(normalized_word, [])
    
    def expand_query_with_synonyms(self, query: str) -> List[str]:
        """Sorguyu sinonimlerle geniÅŸlet"""
        expanded_queries = [query]
        words = query.lower().split()
        
        for word in words:
            synonyms = self.get_synonyms(word)
            if synonyms:
                # Her sinonim iÃ§in yeni sorgu oluÅŸtur
                for synonym in synonyms[:3]:  # Ä°lk 3 sinonim
                    expanded_query = query.replace(word, synonym)
                    if expanded_query not in expanded_queries:
                        expanded_queries.append(expanded_query)
        
        return expanded_queries
    
    def extract_root_words(self, text: str) -> Set[str]:
        """Metinden kÃ¶k kelimeleri Ã§Ä±kar"""
        normalized = self.normalize_text(text)
        words = normalized.split()
        
        root_words = set()
        for word in words:
            if len(word) > 2:  # Ã‡ok kÄ±sa kelimeleri atla
                root_words.add(word)
        
        return root_words
    
    def calculate_turkish_similarity(self, text1: str, text2: str) -> float:
        """TÃ¼rkÃ§e metinler arasÄ± benzerlik hesapla"""
        # Normalize et
        norm1 = self.normalize_text(text1)
        norm2 = self.normalize_text(text2)
        
        # KÃ¶k kelimeleri Ã§Ä±kar
        roots1 = self.extract_root_words(norm1)
        roots2 = self.extract_root_words(norm2)
        
        if not roots1 or not roots2:
            return 0.0
        
        # Jaccard similarity
        intersection = len(roots1.intersection(roots2))
        union = len(roots1.union(roots2))
        
        if union == 0:
            return 0.0
        
        return intersection / union
    
    def enhance_search_terms(self, search_term: str) -> Dict[str, List[str]]:
        """Arama terimini zenginleÅŸtir"""
        normalized = self.normalize_text(search_term)
        
        enhancement = {
            'original': search_term,
            'normalized': normalized,
            'root_words': list(self.extract_root_words(normalized)),
            'synonyms': [],
            'expanded_queries': self.expand_query_with_synonyms(search_term)
        }
        
        # Her kelime iÃ§in sinonimlarÄ± topla
        for word in normalized.split():
            synonyms = self.get_synonyms(word)
            enhancement['synonyms'].extend(synonyms)
        
        # Duplicate'leri temizle
        enhancement['synonyms'] = list(set(enhancement['synonyms']))
        
        return enhancement

# Test fonksiyonu
def test_turkish_rules():
    """Turkish language rules test"""
    
    rules = TurkishLanguageRules()
    
    print("ðŸ‡¹ðŸ‡· Turkish Language Rules Test:")
    print("=" * 40)
    
    # Normalizasyon testleri
    test_texts = [
        "Hamile Lohusa GeceliÄŸi",
        "Dantelli Pijamalar",
        "Siyah TÃ¼llÃ¼ SabahlÄ±klar",
        "GÃ¶ÄŸÃ¼s ve SÄ±rt Dekolteli TakÄ±mÄ±",
        "Pamuklu AskÄ±lÄ± Gecelikler"
    ]
    
    print("\nðŸ“ Text Normalization:")
    for text in test_texts:
        normalized = rules.normalize_text(text)
        print(f"  '{text}' -> '{normalized}'")
    
    # Sinonim testleri
    print("\nðŸ”„ Synonym Expansion:")
    test_words = ['gecelik', 'pijama', 'dantel', 'siyah', 'hamile']
    for word in test_words:
        synonyms = rules.get_synonyms(word)
        print(f"  '{word}': {synonyms[:3]}")  # Ä°lk 3 sinonim
    
    # Sorgu geniÅŸletme testleri
    print("\nðŸ” Query Expansion:")
    test_queries = [
        "siyah gecelik",
        "hamile pijama",
        "dantelli takÄ±m"
    ]
    
    for query in test_queries:
        expanded = rules.expand_query_with_synonyms(query)
        print(f"  '{query}':")
        for exp in expanded[:3]:  # Ä°lk 3 geniÅŸletilmiÅŸ sorgu
            print(f"    -> '{exp}'")
    
    # Benzerlik testleri
    print("\nðŸ“Š Similarity Calculation:")
    similarity_tests = [
        ("hamile geceliÄŸi", "hamile gecelik"),
        ("siyah dantelli", "black lace"),
        ("pijama takÄ±mÄ±", "pajama set")
    ]
    
    for text1, text2 in similarity_tests:
        similarity = rules.calculate_turkish_similarity(text1, text2)
        print(f"  '{text1}' <-> '{text2}': {similarity:.3f}")

if __name__ == "__main__":
    test_turkish_rules()