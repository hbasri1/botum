#!/usr/bin/env python3
"""
Product Feature Extractor - ÃœrÃ¼n isimlerinden otomatik Ã¶zellik Ã§Ä±karma sistemi
"""

import re
import logging
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass
from enum import Enum
try:
    from .turkish_language_rules import TurkishLanguageRules
    from .feature_synonym_mapper import FeatureSynonymMapper
except ImportError:
    from turkish_language_rules import TurkishLanguageRules
    from feature_synonym_mapper import FeatureSynonymMapper

logger = logging.getLogger(__name__)

class FeatureCategory(Enum):
    """Ã–zellik kategorileri"""
    COLOR = "color"
    STYLE = "style"
    MATERIAL = "material"
    SIZE = "size"
    PATTERN = "pattern"
    CLOSURE = "closure"
    NECKLINE = "neckline"
    SLEEVE = "sleeve"
    TARGET_GROUP = "target_group"
    OCCASION = "occasion"
    GARMENT_TYPE = "garment_type"

@dataclass
class ProductFeature:
    """ÃœrÃ¼n Ã¶zelliÄŸi modeli"""
    name: str
    category: FeatureCategory
    value: str
    weight: float
    synonyms: List[str]
    confidence: float = 1.0

class ProductFeatureExtractor:
    """ÃœrÃ¼n isimlerinden otomatik Ã¶zellik Ã§Ä±karma sistemi"""
    
    def __init__(self):
        self.turkish_rules = TurkishLanguageRules()
        self.synonym_mapper = FeatureSynonymMapper()
        self._initialize_feature_patterns()
        self._initialize_synonyms()
        self._initialize_weights()
    
    def _initialize_feature_patterns(self):
        """Ã–zellik Ã§Ä±karma pattern'lerini initialize et"""
        
        # Renk pattern'leri
        self.color_patterns = {
            r'\b(siyah|black)\b': 'siyah',
            r'\b(beyaz|white|ekru)\b': 'beyaz',
            r'\b(kÄ±rmÄ±zÄ±|red|bordo)\b': 'kÄ±rmÄ±zÄ±',
            r'\b(mavi|blue|lacivert|navy)\b': 'mavi',
            r'\b(yeÅŸil|green)\b': 'yeÅŸil',
            r'\b(sarÄ±|yellow|altÄ±n|gold)\b': 'sarÄ±',
            r'\b(pembe|pink|fuÅŸya)\b': 'pembe',
            r'\b(mor|purple|lila)\b': 'mor',
            r'\b(gri|gray|grey)\b': 'gri',
            r'\b(kahverengi|brown|bej|beige)\b': 'kahverengi',
            r'\b(turuncu|orange)\b': 'turuncu',
            r'\b(leopar|leopard)\b': 'leopar',
            r'\b(zebra)\b': 'zebra'
        }
        
        # Stil pattern'leri
        self.style_patterns = {
            r'\b(dekolteli|dekolte)\b': 'dekolteli',
            r'\b(askÄ±lÄ±|askÄ±)\b': 'askÄ±lÄ±',
            r'\b(bol|oversize)\b': 'bol_kesim',
            r'\b(dar|slim|fit)\b': 'dar_kesim',
            r'\b(crop)\b': 'crop',  # Removed "kÄ±sa" to avoid conflict
            r'\b(maxi)\b': 'uzun',  # Removed "uzun" to avoid conflict
            r'\b(mini)\b': 'kÄ±sa',  # Removed "kÄ±sa" to avoid conflict
            r'\b(midi|orta)\b': 'orta_boy',
            r'\b(yÃ¼ksek bel|yÃ¼ksek belli)\b': 'yÃ¼ksek_bel',
            r'\b(dÃ¼ÅŸÃ¼k bel|dÃ¼ÅŸÃ¼k belli)\b': 'dÃ¼ÅŸÃ¼k_bel'
        }
        
        # Malzeme pattern'leri
        self.material_patterns = {
            r'\b(pamuk|cotton|pamuklu)\b': 'pamuk',
            r'\b(ipek|silk)\b': 'ipek',
            r'\b(saten|satin)\b': 'saten',
            r'\b(dantel|dantelli|lace)\b': 'dantel',
            r'\b(tÃ¼l|tÃ¼llÃ¼|tulle)\b': 'tÃ¼l',
            r'\b(kadife|velvet)\b': 'kadife',
            r'\b(deri|leather)\b': 'deri',
            r'\b(jean|denim)\b': 'denim',
            r'\b(Ã¶rme|knit)\b': 'Ã¶rme',
            r'\b(polyester)\b': 'polyester',
            r'\b(viskoz|viscose)\b': 'viskoz',
            r'\b(elastan|spandex)\b': 'elastan',
            r'\b(modal)\b': 'modal',
            r'\b(bambu|bamboo)\b': 'bambu'
        }
        
        # Desen pattern'leri
        self.pattern_patterns = {
            r'\b(Ã§izgili|stripe|striped)\b': 'Ã§izgili',
            r'\b(puantiyeli|polka dot|noktalÄ±)\b': 'puantiyeli',
            r'\b(Ã§iÃ§ekli|floral|flower)\b': 'Ã§iÃ§ekli',
            r'\b(geometrik|geometric)\b': 'geometrik',
            r'\b(etnik|ethnic|afrika|african)\b': 'etnik',
            r'\b(baskÄ±lÄ±|print|printed)\b': 'baskÄ±lÄ±',
            r'\b(dÃ¼z|plain|solid)\b': 'dÃ¼z',
            r'\b(kareli|check|checkered)\b': 'kareli',
            r'\b(leopar|leopard)\b': 'leopar_desen',
            r'\b(zebra)\b': 'zebra_desen'
        }
        
        # Kapama pattern'leri
        self.closure_patterns = {
            r'\b(dÃ¼ÄŸmeli|button|buttoned)\b': 'dÃ¼ÄŸmeli',
            r'\b(fermuarlÄ±|zip|zipper)\b': 'fermuarlÄ±',
            r'\b(baÄŸlamalÄ±|tie|tied)\b': 'baÄŸlamalÄ±',
            r'\b(Ã§Ä±tÃ§Ä±tlÄ±|snap)\b': 'Ã§Ä±tÃ§Ä±tlÄ±',
            r'\b(lastikli|elastic)\b': 'lastikli'
        }
        
        # Yaka pattern'leri - normalized text iÃ§in
        self.neckline_patterns = {
            r'\b(v yak|v neck)\b': 'v_yaka',              # "yaka" -> "yak"
            r'\b(yuvarlak yak|round neck)\b': 'yuvarlak_yaka',
            r'\b(balÄ±k sÄ±rt|halter)\b': 'halter',         # "sÄ±rtÄ±" -> "sÄ±rt"
            r'\b(straplez|strapless)\b': 'straplez',
            r'\b(gÃ¶ÄŸÃ¼s dekolte|chest decollete)\b': 'gÃ¶ÄŸÃ¼s_dekolteli',  # "dekolteli" -> "dekolte"
            r'\b(sÄ±rt dekolte|back decollete)\b': 'sÄ±rt_dekolteli',
            r'\b(omuz dekolte|shoulder decollete)\b': 'omuz_dekolteli',
            r'\b(yakas|yak|collar|neck)\b': 'yaka',       # "yakasÄ±" -> "yakas"
            r'\b(yakas dantel|dantel yak)\b': 'dantelli_yaka'  # normalized versions
        }
        
        # Hedef grup pattern'leri
        self.target_group_patterns = {
            r'\b(hamile|pregnant|maternity)\b': 'hamile',
            r'\b(lohusa|nursing|breastfeeding)\b': 'lohusa',
            r'\b(bÃ¼yÃ¼k beden|plus size)\b': 'bÃ¼yÃ¼k_beden',
            r'\b(genÃ§|teen|teenager)\b': 'genÃ§',
            r'\b(Ã§ocuk|kids|child)\b': 'Ã§ocuk',
            r'\b(bebek|baby)\b': 'bebek'
        }
        
        # Giysi tÃ¼rÃ¼ pattern'leri
        self.garment_type_patterns = {
            r'\b(gecelik|nightgown|nightdress)\b': 'gecelik',
            r'\b(pijama|pajama|pyjama)\b': 'pijama',
            r'\b(sabahlÄ±k|robe|bathrobe)\b': 'sabahlÄ±k',
            r'\b(takÄ±m|takÄ±mÄ±|set|suit)\b': 'takÄ±m',
            r'\b(elbise|dress)\b': 'elbise',
            r'\b(bluz|blouse|top)\b': 'bluz',
            r'\b(tiÅŸÃ¶rt|t-shirt|tshirt)\b': 'tiÅŸÃ¶rt',
            r'\b(ÅŸort|short|shorts)\b': 'ÅŸort',
            r'\b(pantolon|pants|trousers)\b': 'pantolon',
            r'\b(etek|skirt)\b': 'etek',
            r'\b(ceket|jacket)\b': 'ceket',
            r'\b(hÄ±rka|cardigan)\b': 'hÄ±rka',
            r'\b(sÃ¼tyeni|bra)\b': 'sÃ¼tyeni',
            r'\b(kÃ¼lot|panty|underwear)\b': 'kÃ¼lot'
        }
        
        # Kol pattern'leri (ayrÄ± kategori) - normalized text iÃ§in
        self.sleeve_patterns = {
            r'\b(kolsuz)\b': 'kolsuz',
            r'\b(uzun koll|uzun kol)\b': 'uzun_kollu',  # "kollu" -> "koll"
            r'\b(kÄ±s koll|kÄ±sa kol)\b': 'kÄ±sa_kollu',   # "kÄ±sa kollu" -> "kÄ±s koll"
            r'\b(koll|sleeve)\b': 'kollu'               # "kollu" -> "koll"
        }
        
        # Beden pattern'leri
        self.size_patterns = {
            r'\b(xs|extra small)\b': 'XS',
            r'\b(s|small)\b': 'S',
            r'\b(m|medium)\b': 'M',
            r'\b(l|large)\b': 'L',
            r'\b(xl|extra large)\b': 'XL',
            r'\b(xxl|2xl)\b': 'XXL',
            r'\b(xxxl|3xl)\b': 'XXXL',
            r'\b(\d{2,3})\b': 'numeric_size'  # 36, 38, 40 gibi
        }
    
    def _initialize_synonyms(self):
        """Sinonim mapping'lerini initialize et"""
        self.synonyms = {
            # Renk sinonimlarÄ±
            'siyah': ['black', 'kara'],
            'beyaz': ['white', 'ak', 'ekru', 'krem'],
            'kÄ±rmÄ±zÄ±': ['red', 'al', 'bordo', 'crimson'],
            'mavi': ['blue', 'lacivert', 'navy', 'gÃ¶k'],
            'yeÅŸil': ['green', 'yemyeÅŸil'],
            'sarÄ±': ['yellow', 'altÄ±n', 'gold', 'golden'],
            'pembe': ['pink', 'fuÅŸya', 'rose'],
            'mor': ['purple', 'lila', 'violet'],
            'gri': ['gray', 'grey', 'ash'],
            'kahverengi': ['brown', 'bej', 'beige', 'camel'],
            
            # Stil sinonimlarÄ±
            'dekolteli': ['dekolte', 'aÃ§Ä±k yakalÄ±'],
            'askÄ±lÄ±': ['askÄ±', 'strap', 'strappy'],
            'kolsuz': ['sleeveless', 'tank'],
            'uzun_kollu': ['long sleeve', 'uzun kol'],
            'kÄ±sa_kollu': ['short sleeve', 'kÄ±sa kol'],
            
            # Malzeme sinonimlarÄ±
            'dantel': ['dantelli', 'lace', 'gÃ¼pÃ¼r'],
            'tÃ¼l': ['tÃ¼llÃ¼', 'tulle', 'mesh'],
            'pamuk': ['cotton', '100% pamuk'],
            'ipek': ['silk', 'satin'],
            
            # Hedef grup sinonimlarÄ±
            'hamile': ['pregnant', 'maternity', 'anne adayÄ±'],
            'lohusa': ['nursing', 'emziren', 'anne'],
            
            # Giysi tÃ¼rÃ¼ sinonimlarÄ±
            'gecelik': ['nightgown', 'nightdress', 'gece elbisesi'],
            'pijama': ['pajama', 'pyjama', 'ev kÄ±yafeti'],
            'sabahlÄ±k': ['robe', 'bathrobe', 'morning gown'],
            'takÄ±m': ['set', 'suit', 'kombin']
        }
    
    def _initialize_weights(self):
        """Ã–zellik aÄŸÄ±rlÄ±klarÄ±nÄ± initialize et"""
        self.category_weights = {
            FeatureCategory.GARMENT_TYPE: 1.0,  # En Ã¶nemli
            FeatureCategory.TARGET_GROUP: 0.9,
            FeatureCategory.STYLE: 0.8,
            FeatureCategory.MATERIAL: 0.7,
            FeatureCategory.COLOR: 0.6,
            FeatureCategory.PATTERN: 0.5,
            FeatureCategory.NECKLINE: 0.4,
            FeatureCategory.SLEEVE: 0.4,  # Kol Ã¶nemli
            FeatureCategory.CLOSURE: 0.3,
            FeatureCategory.SIZE: 0.2,
            FeatureCategory.OCCASION: 0.1
        }
    
    def extract_features(self, product_text: str) -> List[ProductFeature]:
        """
        ÃœrÃ¼n metninden Ã¶zellikleri Ã§Ä±kar
        
        Args:
            product_text: ÃœrÃ¼n adÄ± veya aÃ§Ä±klamasÄ±
            
        Returns:
            List[ProductFeature]: Ã‡Ä±karÄ±lan Ã¶zellikler
        """
        if not product_text:
            return []
        
        features = []
        # TÃ¼rkÃ§e normalizasyon uygula
        normalized_text = self.turkish_rules.normalize_for_search(product_text)
        text_lower = normalized_text.lower()
        
        # Her kategori iÃ§in pattern matching yap
        pattern_mappings = [
            (self.color_patterns, FeatureCategory.COLOR),
            (self.style_patterns, FeatureCategory.STYLE),
            (self.material_patterns, FeatureCategory.MATERIAL),
            (self.pattern_patterns, FeatureCategory.PATTERN),
            (self.closure_patterns, FeatureCategory.CLOSURE),
            (self.neckline_patterns, FeatureCategory.NECKLINE),
            (self.sleeve_patterns, FeatureCategory.SLEEVE),
            (self.target_group_patterns, FeatureCategory.TARGET_GROUP),
            (self.garment_type_patterns, FeatureCategory.GARMENT_TYPE),
            (self.size_patterns, FeatureCategory.SIZE)
        ]
        
        for patterns, category in pattern_mappings:
            for pattern, feature_value in patterns.items():
                if re.search(pattern, text_lower, re.IGNORECASE):
                    # Confidence hesapla (pattern match kalitesine gÃ¶re)
                    confidence = self._calculate_confidence(pattern, text_lower)
                    
                    # Weight al
                    weight = self.category_weights.get(category, 0.5)
                    
                    # SinonimlarÄ± al (kendi sinonimler + TÃ¼rkÃ§e kurallar + synonym mapper)
                    synonyms = self.synonyms.get(feature_value, [])
                    turkish_synonyms = self.turkish_rules.get_synonyms(feature_value)
                    mapper_synonyms = self.synonym_mapper.get_synonyms(feature_value)
                    
                    synonyms.extend(turkish_synonyms)
                    synonyms.extend(mapper_synonyms)
                    synonyms = list(set(synonyms))  # Duplicate'leri temizle
                    
                    # Feature value'yu normalize et
                    normalized_value = self.synonym_mapper.normalize_feature_value(feature_value)
                    
                    feature = ProductFeature(
                        name=normalized_value,
                        category=category,
                        value=normalized_value,
                        weight=weight,
                        synonyms=synonyms,
                        confidence=confidence
                    )
                    
                    features.append(feature)
        
        # Ã–zel kombinasyon kurallarÄ±
        features.extend(self._extract_combination_features(text_lower))
        
        # Duplicate'leri temizle
        features = self._deduplicate_features(features)
        
        logger.info(f"Extracted {len(features)} features from: {product_text[:50]}...")
        return features
    
    def _calculate_confidence(self, pattern: str, text: str) -> float:
        """Pattern match confidence'Ä±nÄ± hesapla"""
        matches = re.findall(pattern, text, re.IGNORECASE)
        if not matches:
            return 0.0
        
        # Basit confidence hesaplama
        # Daha fazla match = daha yÃ¼ksek confidence
        base_confidence = min(len(matches) * 0.3 + 0.7, 1.0)
        
        # Pattern karmaÅŸÄ±klÄ±ÄŸÄ±na gÃ¶re bonus
        if len(pattern) > 20:  # KarmaÅŸÄ±k pattern
            base_confidence += 0.1
        
        return min(base_confidence, 1.0)
    
    def _extract_combination_features(self, text: str) -> List[ProductFeature]:
        """Ã–zel kombinasyon Ã¶zelliklerini Ã§Ä±kar"""
        features = []
        
        # "hamile lohusa" kombinasyonu
        if re.search(r'\b(hamile.*lohusa|lohusa.*hamile)\b', text):
            feature = ProductFeature(
                name='hamile_lohusa',
                category=FeatureCategory.TARGET_GROUP,
                value='hamile_lohusa',
                weight=0.95,
                synonyms=['maternity', 'anne', 'pregnancy'],
                confidence=0.9
            )
            features.append(feature)
        
        # "gÃ¶ÄŸÃ¼s ve sÄ±rt dekolteli" kombinasyonu
        if re.search(r'\b(gÃ¶ÄŸÃ¼s.*sÄ±rt.*dekolteli|sÄ±rt.*gÃ¶ÄŸÃ¼s.*dekolteli)\b', text):
            feature = ProductFeature(
                name='gÃ¶ÄŸÃ¼s_sÄ±rt_dekolteli',
                category=FeatureCategory.NECKLINE,
                value='gÃ¶ÄŸÃ¼s_sÄ±rt_dekolteli',
                weight=0.8,
                synonyms=['front_back_decollete', 'aÃ§Ä±k yakalÄ±'],
                confidence=0.9
            )
            features.append(feature)
        
        # "dantelli ve tÃ¼llÃ¼" kombinasyonu
        if re.search(r'\b(dantelli.*tÃ¼llÃ¼|tÃ¼llÃ¼.*dantelli)\b', text):
            feature = ProductFeature(
                name='dantelli_tÃ¼llÃ¼',
                category=FeatureCategory.MATERIAL,
                value='dantelli_tÃ¼llÃ¼',
                weight=0.7,
                synonyms=['lace_tulle', 'sÃ¼slÃ¼'],
                confidence=0.8
            )
            features.append(feature)
        
        return features
    
    def _deduplicate_features(self, features: List[ProductFeature]) -> List[ProductFeature]:
        """Duplicate Ã¶zellikleri temizle"""
        seen = set()
        unique_features = []
        
        for feature in features:
            # AynÄ± kategori ve deÄŸer kombinasyonu
            key = (feature.category, feature.value)
            if key not in seen:
                seen.add(key)
                unique_features.append(feature)
        
        return unique_features
    
    def categorize_features(self, features: List[ProductFeature]) -> Dict[str, List[ProductFeature]]:
        """Ã–zellikleri kategorilere gÃ¶re grupla"""
        categorized = {}
        
        for feature in features:
            category_name = feature.category.value
            if category_name not in categorized:
                categorized[category_name] = []
            categorized[category_name].append(feature)
        
        return categorized
    
    def create_feature_embeddings(self, features: List[ProductFeature]) -> Dict[str, List[float]]:
        """Ã–zellikler iÃ§in embeddings oluÅŸtur (mock implementation)"""
        embeddings = {}
        
        for feature in features:
            # Mock embedding generation
            import hashlib
            import random
            
            # Deterministic embedding
            seed = int(hashlib.md5(feature.value.encode()).hexdigest()[:8], 16)
            random.seed(seed)
            embedding = [random.uniform(-1, 1) for _ in range(384)]  # Smaller dimension
            
            embeddings[feature.value] = embedding
        
        return embeddings
    
    def weight_features(self, features: List[ProductFeature]) -> Dict[str, float]:
        """Ã–zelliklerin aÄŸÄ±rlÄ±klarÄ±nÄ± hesapla"""
        weights = {}
        
        for feature in features:
            # Base weight + confidence bonus
            final_weight = feature.weight * feature.confidence
            weights[feature.value] = final_weight
        
        return weights
    
    def get_feature_synonyms(self, feature_value: str) -> List[str]:
        """Ã–zellik iÃ§in sinonimlarÄ± getir"""
        return self.synonyms.get(feature_value, [])
    
    def enhance_product_with_features(self, product: Dict[str, Any]) -> Dict[str, Any]:
        """ÃœrÃ¼nÃ¼ Ã§Ä±karÄ±lan Ã¶zelliklerle zenginleÅŸtir"""
        enhanced_product = product.copy()
        
        # ÃœrÃ¼n adÄ±ndan Ã¶zellikleri Ã§Ä±kar
        product_name = product.get('name', '')
        features = self.extract_features(product_name)
        
        # Ã–zellikleri Ã¼rÃ¼ne ekle
        enhanced_product['extracted_features'] = [
            {
                'name': f.name,
                'category': f.category.value,
                'value': f.value,
                'weight': f.weight,
                'confidence': f.confidence,
                'synonyms': f.synonyms
            }
            for f in features
        ]
        
        # Kategorize edilmiÅŸ Ã¶zellikleri ekle
        categorized = self.categorize_features(features)
        enhanced_product['feature_categories'] = {
            category: [f.value for f in features_list]
            for category, features_list in categorized.items()
        }
        
        # AÄŸÄ±rlÄ±klarÄ± ekle
        weights = self.weight_features(features)
        enhanced_product['feature_weights'] = weights
        
        # Arama iÃ§in zenginleÅŸtirilmiÅŸ metin oluÅŸtur
        enhanced_product['search_enhanced_text'] = self._create_search_text(product, features)
        
        return enhanced_product
    
    def _create_search_text(self, product: Dict[str, Any], features: List[ProductFeature]) -> str:
        """Arama iÃ§in zenginleÅŸtirilmiÅŸ metin oluÅŸtur"""
        text_parts = []
        
        # Orijinal Ã¼rÃ¼n adÄ±
        if name := product.get('name'):
            text_parts.append(name)
        
        # Ã‡Ä±karÄ±lan Ã¶zellikler
        for feature in features:
            text_parts.append(feature.value)
            text_parts.extend(feature.synonyms)
        
        # Mevcut Ã¼rÃ¼n bilgileri
        for field in ['category', 'color', 'material', 'description']:
            if value := product.get(field):
                text_parts.append(str(value))
        
        return ' '.join(text_parts)
    
    def get_extraction_stats(self) -> Dict[str, Any]:
        """Feature extraction istatistikleri"""
        return {
            'total_patterns': sum([
                len(self.color_patterns),
                len(self.style_patterns),
                len(self.material_patterns),
                len(self.pattern_patterns),
                len(self.closure_patterns),
                len(self.neckline_patterns),
                len(self.target_group_patterns),
                len(self.garment_type_patterns),
                len(self.size_patterns)
            ]),
            'categories': len(FeatureCategory),
            'synonyms_count': sum(len(syns) for syns in self.synonyms.values()),
            'category_weights': {cat.value: weight for cat, weight in self.category_weights.items()}
        }

# Test fonksiyonu
def test_feature_extraction():
    """Feature extraction sistemini test et"""
    
    extractor = ProductFeatureExtractor()
    
    # Test Ã¼rÃ¼nleri
    test_products = [
        "Afrika Etnik BaskÄ±lÄ± Dantelli 'Africa Style' Gecelik",
        "Dantelli Ã–nÃ¼ DÃ¼ÄŸmeli Hamile Lohusa Gecelik",
        "GÃ¶ÄŸÃ¼s ve SÄ±rt Dekolteli Brode Dantelli Åort TakÄ±mÄ±",
        "Siyah TÃ¼llÃ¼ AskÄ±lÄ± Gecelik",
        "Beyaz Pamuklu Uzun Kollu Pijama TakÄ±mÄ±"
    ]
    
    print("ğŸ§ª Product Feature Extraction Test:")
    print("=" * 50)
    
    for product_name in test_products:
        print(f"\nğŸ“¦ Product: {product_name}")
        features = extractor.extract_features(product_name)
        
        if features:
            print(f"âœ… Extracted {len(features)} features:")
            for feature in features:
                print(f"  â€¢ {feature.category.value}: {feature.value} "
                      f"(weight: {feature.weight:.2f}, confidence: {feature.confidence:.2f})")
                if feature.synonyms:
                    print(f"    Synonyms: {', '.join(feature.synonyms[:3])}")
        else:
            print("âŒ No features extracted")
        
        # Kategorize edilmiÅŸ Ã¶zellikleri gÃ¶ster
        categorized = extractor.categorize_features(features)
        if categorized:
            print("ğŸ“Š Categorized features:")
            for category, cat_features in categorized.items():
                values = [f.value for f in cat_features]
                print(f"  â€¢ {category}: {', '.join(values)}")
    
    # Ä°statistikleri gÃ¶ster
    stats = extractor.get_extraction_stats()
    print(f"\nğŸ“ˆ Extraction Stats:")
    print(f"  â€¢ Total patterns: {stats['total_patterns']}")
    print(f"  â€¢ Categories: {stats['categories']}")
    print(f"  â€¢ Synonyms: {stats['synonyms_count']}")

if __name__ == "__main__":
    # Test iÃ§in relative import'larÄ± dÃ¼zelt
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    
    from turkish_language_rules import TurkishLanguageRules
    from feature_synonym_mapper import FeatureSynonymMapper
    
    # Test'i Ã§alÄ±ÅŸtÄ±r
    test_feature_extraction()