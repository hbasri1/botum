#!/usr/bin/env python3
"""
Learning System Test - Kendi kendine Ã¶ÄŸrenen sistem testleri
"""

import asyncio
import json
import time
from datetime import datetime
from services.llm_service import LLMService
from services.learning_service import LearningService
from services.cache_manager import CacheManager
from services.database_service import DatabaseService
from services.session_manager import SessionManager

async def test_llm_learning():
    """LLM Ã¶ÄŸrenme sistemini test et"""
    print("ğŸ§  LLM Ã–ÄŸrenme Sistemi Testi...")
    
    llm_service = LLMService()
    
    # Test mesajlarÄ± - farklÄ± senaryolar
    test_messages = [
        ("merhaba", "greeting", 0.95),
        ("gecelik fiyatÄ± ne kadar?", "product_query", 0.88),
        ("bu ÅŸeyin fiyatÄ± ne kadar?", "product_query", 0.65),  # DÃ¼ÅŸÃ¼k gÃ¼ven
        ("ÅŸikayet etmek istiyorum", "sikayet_bildirme", 0.92),
        ("teÅŸekkÃ¼rler", "thanks", 0.93),
        ("asdfgh qwerty", "unknown", 0.35),  # Ã‡ok dÃ¼ÅŸÃ¼k gÃ¼ven
    ]
    
    print("    Test mesajlarÄ± iÅŸleniyor...")
    
    for i, (message, expected_intent, expected_confidence) in enumerate(test_messages, 1):
        session_id = f"learning-test-{i}"
        
        # LLM'e gÃ¶nder
        response = await llm_service.process_message(
            prompt=f"[session: {session_id}] [kimlik: test-business] {message}",
            session_id=session_id,
            isletme_id="test-business"
        )
        
        if response:
            actual_intent = response.get("intent")
            actual_confidence = response.get("confidence", 0)
            
            print(f"      {i}. '{message}' â†’ {actual_intent} (gÃ¼ven: {actual_confidence:.2f})")
            
            # Beklenen sonuÃ§larÄ± kontrol et
            if actual_intent == expected_intent:
                print(f"         âœ… Intent doÄŸru")
            else:
                print(f"         âŒ Intent yanlÄ±ÅŸ (beklenen: {expected_intent})")
            
            if abs(actual_confidence - expected_confidence) < 0.1:
                print(f"         âœ… GÃ¼ven skoru uygun")
            else:
                print(f"         âš ï¸  GÃ¼ven skoru farklÄ± (beklenen: {expected_confidence})")
        else:
            print(f"      {i}. '{message}' â†’ âŒ LLM yanÄ±t vermedi")
    
    # Ã–ÄŸrenme iÃ§gÃ¶rÃ¼lerini al
    print("\n    Ã–ÄŸrenme iÃ§gÃ¶rÃ¼leri alÄ±nÄ±yor...")
    insights = await llm_service.get_learning_insights()
    
    print(f"      Toplam etkileÅŸim: {insights.get('total_interactions', 0)}")
    print(f"      BaÅŸarÄ± oranÄ±: %{insights.get('success_rate', 0) * 100:.1f}")
    print(f"      Ortalama gÃ¼ven: {insights.get('overall_metrics', {}).get('average_confidence', 0):.2f}")
    
    intent_dist = insights.get('intent_distribution', {})
    if intent_dist:
        print(f"      Intent daÄŸÄ±lÄ±mÄ±:")
        for intent, count in intent_dist.items():
            print(f"        - {intent}: {count}")
    
    recommendations = insights.get('recommendations', [])
    if recommendations:
        print(f"      Ã–neriler:")
        for rec in recommendations[:3]:
            print(f"        - {rec}")
    
    print("    âœ… LLM Ã¶ÄŸrenme sistemi testi tamamlandÄ±!")

async def test_learning_service():
    """Learning Service'i test et"""
    print("\nğŸ“š Learning Service Testi...")
    
    # Servisleri baÅŸlat
    cache_manager = CacheManager()
    session_manager = SessionManager()
    db_service = DatabaseService(cache_manager=cache_manager)
    llm_service = LLMService()
    learning_service = LearningService(db_service, llm_service, cache_manager)
    
    # Ã–nce bazÄ± test verileri oluÅŸtur
    print("    Test verileri oluÅŸturuluyor...")
    
    test_interactions = [
        ("merhaba", "greeting", 0.95),
        ("gecelik fiyatÄ±", "product_query", 0.88),
        ("iade politikasÄ±", "meta_query", 0.91),
        ("ÅŸikayet", "sikayet_bildirme", 0.92),
        ("belirsiz mesaj", "unknown", 0.45),
    ]
    
    # Test etkileÅŸimlerini simÃ¼le et
    for message, intent, confidence in test_interactions:
        for i in range(3):  # Her mesajÄ± 3 kez tekrarla
            await llm_service.process_message(
                prompt=f"[session: test-{i}] [kimlik: test-business] {message}",
                session_id=f"test-{i}",
                isletme_id="test-business"
            )
    
    print("    Pattern analizi yapÄ±lÄ±yor...")
    
    # Pattern analizini manuel olarak tetikle
    await learning_service._analyze_interaction_patterns()
    await learning_service._analyze_performance_metrics()
    await learning_service._optimize_cache_patterns()
    await learning_service._analyze_intent_accuracy()
    await learning_service._generate_improvement_suggestions()
    
    # Learning raporu al
    print("    Learning raporu alÄ±nÄ±yor...")
    report = await learning_service.get_learning_report()
    
    detected_patterns = report.get('detected_patterns', {})
    
    # Intent patterns
    intent_patterns = detected_patterns.get('intent_patterns', {})
    print(f"      Tespit edilen intent pattern'leri: {len(intent_patterns)}")
    
    for pattern_key, pattern_data in list(intent_patterns.items())[:3]:
        print(f"        - {pattern_key}: {pattern_data['count']} kez, gÃ¼ven: {pattern_data['avg_confidence']:.2f}")
    
    # Performance issues
    perf_issues = detected_patterns.get('performance_issues', [])
    print(f"      Performance sorunlarÄ±: {len(perf_issues)}")
    
    for issue in perf_issues:
        print(f"        - {issue['type']}: {issue['recommendation']}")
    
    # Improvement suggestions
    suggestions = report.get('improvement_suggestions', [])
    print(f"      GeliÅŸim Ã¶nerileri: {len(suggestions)}")
    
    for suggestion in suggestions[:3]:
        print(f"        - {suggestion['type']} ({suggestion['priority']}): {suggestion['description']}")
    
    print("    âœ… Learning service testi tamamlandÄ±!")

async def test_fine_tuning_data_export():
    """Fine-tuning data export'unu test et"""
    print("\nğŸ“¤ Fine-tuning Data Export Testi...")
    
    llm_service = LLMService()
    cache_manager = CacheManager()
    db_service = DatabaseService(cache_manager=cache_manager)
    learning_service = LearningService(db_service, llm_service, cache_manager)
    
    # Ã–nce bazÄ± kaliteli etkileÅŸimler oluÅŸtur
    quality_interactions = [
        ("merhaba", "greeting", 0.95),
        ("gecelik fiyatÄ± ne kadar", "product_query", 0.88),
        ("iade politikanÄ±z nedir", "meta_query", 0.91),
        ("telefon numaranÄ±z", "meta_query", 0.89),
        ("teÅŸekkÃ¼r ederim", "thanks", 0.93),
    ]
    
    print("    Kaliteli etkileÅŸimler oluÅŸturuluyor...")
    
    for message, intent, confidence in quality_interactions:
        for i in range(5):  # Her mesajÄ± 5 kez tekrarla
            await llm_service.process_message(
                prompt=f"[session: export-test-{i}] [kimlik: export-business] {message}",
                session_id=f"export-test-{i}",
                isletme_id="export-business"
            )
    
    # Training data export et
    print("    Training data export ediliyor...")
    
    export_data = await learning_service.export_fine_tuning_data()
    
    training_data = export_data.get('training_data', {})
    pattern_examples = export_data.get('pattern_examples', [])
    
    print(f"      Training examples: {len(training_data.get('training_examples', []))}")
    print(f"      Pattern examples: {len(pattern_examples)}")
    print(f"      Toplam examples: {export_data.get('total_examples', 0)}")
    
    # Ã–rnek training data gÃ¶ster
    examples = training_data.get('training_examples', [])
    if examples:
        print(f"      Ã–rnek training data:")
        for example in examples[:3]:
            input_text = example.get('input', '')[:50]
            output_intent = example.get('output', {}).get('intent', '')
            confidence = example.get('output', {}).get('confidence', 0)
            print(f"        - '{input_text}...' â†’ {output_intent} ({confidence:.2f})")
    
    # Pattern examples gÃ¶ster
    if pattern_examples:
        print(f"      Ã–rnek pattern data:")
        for example in pattern_examples[:3]:
            input_text = example.get('input', '')[:50]
            output_intent = example.get('output', {}).get('intent', '')
            confidence = example.get('output', {}).get('confidence', 0)
            print(f"        - '{input_text}...' â†’ {output_intent} ({confidence:.2f})")
    
    print("    âœ… Fine-tuning data export testi tamamlandÄ±!")

async def test_performance_monitoring():
    """Performance monitoring'i test et"""
    print("\nğŸ“Š Performance Monitoring Testi...")
    
    llm_service = LLMService()
    
    # FarklÄ± performance senaryolarÄ±
    scenarios = [
        ("YÃ¼ksek performans", [
            ("merhaba", 0.95),
            ("teÅŸekkÃ¼rler", 0.93),
            ("gecelik fiyatÄ±", 0.88),
        ]),
        ("Orta performans", [
            ("bu Ã¼rÃ¼n", 0.75),
            ("ne kadar", 0.72),
            ("bilgi", 0.78),
        ]),
        ("DÃ¼ÅŸÃ¼k performans", [
            ("asdfgh", 0.35),
            ("belirsiz", 0.45),
            ("karmaÅŸÄ±k soru", 0.55),
        ])
    ]
    
    print("    FarklÄ± performance senaryolarÄ± test ediliyor...")
    
    for scenario_name, messages in scenarios:
        print(f"      {scenario_name} senaryosu:")
        
        for message, expected_conf in messages:
            response = await llm_service.process_message(
                prompt=f"[session: perf-test] [kimlik: perf-business] {message}",
                session_id="perf-test",
                isletme_id="perf-business"
            )
            
            if response:
                actual_conf = response.get("confidence", 0)
                intent = response.get("intent", "unknown")
                
                if actual_conf >= 0.80:
                    status = "âœ… Normal"
                elif actual_conf >= 0.60:
                    status = "âš ï¸  DÃ¼ÅŸÃ¼k"
                else:
                    status = "âŒ Eskalasyon"
                
                print(f"        - '{message}' â†’ {intent} ({actual_conf:.2f}) {status}")
    
    # Model bilgilerini al
    print("    Model performans metrikleri:")
    model_info = await llm_service.get_model_info()
    
    perf_metrics = model_info.get("performance_metrics", {})
    print(f"      Toplam istek: {perf_metrics.get('total_requests', 0)}")
    print(f"      BaÅŸarÄ±lÄ± istek: {perf_metrics.get('successful_requests', 0)}")
    print(f"      BaÅŸarÄ±sÄ±z istek: {perf_metrics.get('failed_requests', 0)}")
    print(f"      Ortalama gÃ¼ven: {perf_metrics.get('average_confidence', 0):.2f}")
    print(f"      Memory size: {model_info.get('memory_size', 0)} etkileÅŸim")
    
    print("    âœ… Performance monitoring testi tamamlandÄ±!")

async def main():
    """Ana test fonksiyonu"""
    print("ğŸš€ LEARNING SYSTEM KAPSAMLI TESTLERÄ°")
    print("=" * 60)
    print("Bu testler sistemin kendi kendine Ã¶ÄŸrenme kabiliyetini test eder")
    print("=" * 60)
    
    try:
        await test_llm_learning()
        await test_learning_service()
        await test_fine_tuning_data_export()
        await test_performance_monitoring()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ TÃœM LEARNING SYSTEM TESTLERÄ° BAÅARILI!")
        print("=" * 60)
        
        print("\nğŸ“‹ Ã–ZETLÄ° SONUÃ‡LAR:")
        print("âœ… LLM Ã¶ÄŸrenme sistemi Ã§alÄ±ÅŸÄ±yor")
        print("âœ… Pattern detection aktif")
        print("âœ… Performance monitoring Ã§alÄ±ÅŸÄ±yor")
        print("âœ… Fine-tuning data export hazÄ±r")
        print("âœ… Auto-improvement Ã¶nerileri Ã¼retiliyor")
        
        print("\nğŸš€ SÄ°STEM HAZIR:")
        print("- Kendi kendine Ã¶ÄŸreniyor")
        print("- Pattern'leri tespit ediyor")
        print("- Performance'Ä± izliyor")
        print("- Fine-tuning iÃ§in veri hazÄ±rlÄ±yor")
        print("- Otomatik iyileÅŸtirmeler Ã¶neriyor")
        
    except Exception as e:
        print(f"\nâŒ Test hatasÄ±: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())